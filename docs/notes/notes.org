* general thoughts

We want our metric for partial biological function to satisfy the following desiderata (required properties):

1. Metric must reflect selective force over history, not effect of drift
2. Metric must be graded/continuous (accounts for the fact that selective forces can vary in strength)
3. Traits can have multiple commensurable functions (a trait may have multiple effects, each of which partially explain why the trait exists)
4. Metric must be a increasing monotonic function of increasing selective force
5. Metric must be surjective function (each selective force maps onto a single metric value).
6. Generalisability/contextualism (can be applied to multiple evolutionary scenarios)
7. Must be able to apply metric to a single realised evolutionary trajectory

The first because we must be able to distinguish between selection/drift (selected for/selected of, etc.).
The second and third because they reflect the reality of selection by natural selection.
The fourth because biological function is meant to be proportional to the degree to which that effect of the trait was involved in selection.
The fifth because we must be able to map back from the metric to a unique set of model parameter values.
The sixth because we want to be able to apply the metric to a range of theoretical scenarios in which we might ask questions about biological function.
The seventh because, in order to apply the metric to any /actual/ case of evolution, we only have a single realized trajectory to work with.

Functions can thus be partial in several senses.
First, even if a trait only has one function, the degree to which the function has been selected is a graded notion (other things, such as drift, are involved in the spread of a trait).
Second, a trait may have multiple functions, in which case each will partially contribute to selection on the trait.
Third, selection on a trait may be due, in part, to selection on other traits (e.g. genetic linkage (hitchhiking), different traits sharing genetic elements), in which case a trait's function only forms a part of selection on the trait.
Fourth, selection on the trait might have changed over time, or it might differ between environments (this one isn't really a justification for partial functions but rather for decomposing total function so as to better understand the contributions).

Desired characteristics:
- can account for a trait's evolution as well as its maintenance
- can account for a trait going extinct more slowly than another

A candidate that fulfils these criteria is fixation probability, or as we will implement it, a modified form that is better described as a probability of being within a specified range  (i.e. 1 - probability-allele-of-interest-is-not-within-specified-frequency-range; this is in order to account for the case of polymorphisms where we might want to ask a question like "why is allele x maintained at 30% +/- 5%?").

Some decisions that will need to be made:
- How to scale metric? Metric = 0 should be drift; Metric = -1 should be fix_prob of ~0; Metric = +1 should be "paradigmatic" function (this latter one will be the most arbitrary---I could choose selection coefficient of 1, not_lost_prob of 1, or just choose a value based off of the mutational distribution of fitness effects; for all but the latter, I'd probably have to log transform in order to avoid having tiny metric values for everything)
- Balance between a selective expectation (needed to disentangle realized from expected fitness) and explanation of /actual/ evolutionary history (which requires explicit specification of explanatory depth and what to marginalise over). Pure propensity interpretations go too far towards function being an expectation over all possible trajectories that life could have taken (even though the vast majority will not occur). Pure selected effects interpretations would require a metaphysical specification of all possible environmental states that actually occurred, which is obviously infeasible. My approach requires a balance of the two (set the explanatory depth (e.g. grain of description of the environments to consider), record the observed environmental states, and calculate the expected fitness over those realised environmental states.
- Will require specification of selection regime (effectively an evolutionary history), which includes the explanatory depth (e.g. description of environments and observed environmental states), as well as the period of time to consider

What are some potentially interesting cases that I might want to use the metric to compare?
- Single locus, haploid (two allele), each with one effect---simplest setup
- Single locus, diploid (three genotypes), each with one effect, that share an underlying allele (e.g. sickle cell)
- Single locus, haploid (two allele), two different environments. Two sources (alleles), each with four different outcomes, and a single target with two outcomes.
  + Single locus, haploid (two allele), two different (but temporally overlapping) environments (with each allele having an effect in each environment---e.g. bet-hedging). Not sure how this will go if I have to specify the particular environmental states (i.e. stop short of propensity). Each allele will  (A consideration here is whether the effect in each environment should count as a separate function, as arguably a trait might be performing the same action, it just has different effects in the two environments.)
  + Single locus, haploid (two allele) two different (and temporally separated) environments (with each allele having an effect in each environment---e.g. exaptation/vestigial). (A consideration here is whether the effect in each environment should count as a separate function, as arguably a trait might be performing the same action, it just has different effects over the evolutionary history.)
- Single locus, haploid, two effects (e.g. the fitness of allele /a/ is $1 + s_{a1} + s_{a2}$). Two sources, each with four outcomes, and a single target with two outcomes.

I had initially set up the metric for a single fixation event, but a potential problem quickly arose. 
What if an allele was maintained indefinitely (either at a polymorphism or being fixed)? 
I only assign metric values based on individual ``competitions''.
If something ``wins'' multiple competitions, how do I reflect this? Do I then allow function values of individual events to accumulate additively?

Instead, I've decided to take a different approach and simply set the metric relative to a investigator-determined set of conditions.
I then lose the simplicity of having the metric defined relative to the simplest Wright-Fisher model, which would have been nice because of the analogy with effective population size.
Although I originally liked the analogy with $N_e$, I then can no longer compare models over different regimes (if I have to do an additive metric, then something that is maintained in the population for a long time could have an arbitrarily high metric value).
Taking this approach makes it very easy to standardise the metric between -1 and 1 for any arbitrary regime (of course it raises a serious concern as to how one would ever infer a generative model/regime and parameter values for that model in the real world but that's always going to be an issue).

I suppose it would be possible to set it up for comparison with the simple Wright-Fisher model---valid for a single sweep---but this isn't ideal because I'd need to infer both the selection coefficient and the population size.
This differs from effective population size, which assumes neutrality and only has to estimate the population size.
I think this weakens the analogy because in the function case one might have different combinations of population size and selection coefficients that give similar patterns (i.e. a non-unique mapping).
Not an issue for the approach that I'll take---as this is simply inferring the parameters of a specified model---but more of an issue with the model is unspecified, which is what would be the case for the effective population size analogy.

** 202000601 thoughts
   - Instead of log-scaling, I might consider a sigmoid function, as it has a lot of desirable properties (in particular it is bounded between 0 and 1 and it is more sensitive to values around a function value of 0).
     I'll have to decide whether I want the function value to be unbounded above and below (as occurs with the sigmoid function) or whether I should truncate the function (e.g. stretch it horizontally and vertically such that it crosses fix = 1 when function = 1 and fix = 0 when function = -1. In both caess, I'll be comparing all scenarios with a standard reference point, which isn't really desirable (e.g. the longer the time frame we consider, the lower the function value). Perhaps the best option is to use a stretched sigmoid that is bounded at a selection coefficient of 1 (this is, unfortunately, arbitrary). I could also bound the bottom with a selection coefficient of -1. This is nice for symmetry purposes and in fact for the simplest case would simply reduce the function metric to the selection coefficient (but this gets a little messier for some of the other scenarios, e.g. for haploid two effects it would need to be s1 + s2 = -1...this is fine here but it would be problematic if you allowed non-linear interactions, such as with epistasis, so I suspect this isn't very generalisable.).
   - For the haploid two environment model, the selection coefficient of the allele matched to the  /first/ environment matters (overwhelmingly) the most. This makes total sense, as a mutant is most liable to be lost in the first few generations (it doesn't matter if it has a larger fitness advantage later on if it goes extinct before then). This, however, is the opposite of what selected effect theorists believe---to them, the recent history is the most important factor. The problem is related to what one means when they say "the evolution of a trait". In my framework here, this means the probability that a mutant (instantiation of a trait) remains in the population. But when a selected effect theorist refers to a "trait", they are slapping a vague label on a phenotype that roughly corresponds to what they are interested in. For example, I can trace a unique path through evolution leading to the evolution of a (specific lineage of a) human heart. But there could have many evolutionary paths that might have led to an organ that philosophers would call a "heart". A way to draw the distinction is if I were to consider a scenario in which there are multiple recurrent mutations from "non-heart" to "heart"---even if most go extinct, if there are enough recurrent mutations and the advantage of "heart" is sufficient, then I can construct a scenario in which there is a probability of 1 that a heart will evolve. SE theorists, I think, implicitly include some of these non-adaptive effects in their ascription of function. For example, consider developing antibiotic resistence in bacteria. Given the huge population sizes of bacteria, we can be quite sure that some mutuation(s) will lead to antibiotic resistence, even though the vast majority of mutations that might lead to antibiotic resistence will go extinct due to drift. If our trait is "antibiotic resistence" then we don't care about the actual genotype underlying the trait (and there could be a HUGE number of unique changes that would map to vague phenotype "antibiotic resistence"). So if a SE theorist wants to tell a story about antibiotic resistence, then they need to acknowledge that they are conditioning on the outcome and then retrofitting a story about why that outcome was so likely. The problem here is that even if the meta-outcome (antibiotic resistence) is almost guaranteed given enough time, the specific outcome (specific genotype to a specific phenotype that is a member of set "antibiotic resistence") is far from guaranteed. This then creates a whole host of problems for SE theorists because if they just want to condition on an outcome, then they need to adopt a propensity point of view, something they avowedly reject. But I think I can still justify my results regardless. For example, I think it is justified to say that feathers might never have be used in flying if they had never had an advantage wrt insulation (and that they might still exist solely for insulation if evolution had take a different path). As to how to deal with this in the paper, I think I just ignore it quantitatively, and just point this out in the discussion (and point out that it's future work that SE theorists need to consider). Note that this also relates a bit to the problem of a trait changing over time (e.g. the human heart now is vastly different from the first heart in the last common ancestor of all hearted organisms). 

If mutation is rare, I think it is justified to say that function in the distant history should be more heavily weighted.
If mutation is common and/or the trait designation is sufficiently general such that the genotype -> phenotype mapping is vast, I don't really think that this should affect our function ascription. I think it is conflating adaptive explanations for why /this particular trait evolved/ with other factors relating to the nature of the question and the probability that the trait will arise in the population.

Note that another way of describing my modelling assumptions is that a mutation leading to a function is vanishingly rare (such that you only get one shot). If mutation is common and/or there are many genotype to phenotype mappings, then we have a different scenario more akin to antibiotic resistence. I think a strong case here can be made that SE theorists conflat adaptive explanations (advantage of a instantiation of a trait) and non-adaptive explanations (population sizes, mutation rate, genotype to phenotype mappings, etc.). If they want to say that recent history should be privileged, then basically I think they are conditioning on a trait already being present at a non-trivial frequency in the population, which is asking a different question than I am asking here (i.e. instead of starting with a single organism with the new trait, they are conditioning on those trajectories that have made it to a proportion >x). I think the only way to deal with this is to point it out and to highlight how a function ascription is relavitised to the scenario being explored (e.g. for SE theorists they might be conditioning on a trait that has made it to >x proportion...this again creates problems with the fact that it just obscures very important information about the evolutionary trajectory (for example, what if the trait was deleterious and you've just conditioned on an incredibly lucky instance of that?)).

I should point out that there's nothing wrong with an approach that considers recurrent mutation in the evolution of a trait. I do that all the time in my models. But again it explicitly requires a propensity approach (i.e. we don't say that we're considering the exact evolution history, like what SE theorists want to say, but rather we say we're considering a general model of the history, which is true in spirit but not in details). Incidentally, I don't think this is going to solve the problem with recent history being less important though. I'd expect that the selection coefficient of hte first environment will always be much more important even with recurrent mutation. So there are a few different issues here that need to be clearly described (opposite inference wrt history, trait changing composition over time, factors other than selection on single trait mutation being important, explicating question and scenario to be examined (e.g. how SE theorists implicitly condition on traits that have already spread, etc.)

I think the desire that SE theorists have to prioritise recent function has reasonable motivation. If we consider a realistic trait, then the underlying genotype (and specific phenotype) is constantly changing over evolutionary time. In this scenario, it does make some sense to priviledge the more recent past because changes in the recent past are more closely aligned with recent changes in the trait's phenotype. E.g. bird feathers---when we ask what is the function of bird feathers, we (implicitly) are asking, at least in part, why are bird feathers the way they are in modern birds? Well a good portion of that answer will come from recent evolutionary changes in bird feathers due to selection on properties related to flight. But this is never explicated and would require an extension of the quantitative theory that I'll outline in this paper.

I think that there is also a connection between conditioning on a trait that has reached a proportion of >x and recurrent mutation/other non-adaptive factors influencing probability that trait spreads. In both cases, it seems almost inevitable that a trait will evolve (and that this evolution will be influenced by selection). In both cases, there's also some important non-adaptive dynamics that are omitted. This is a separate issue from the one above, however, and frankly I'd rather not address it if possible (it's messy and doesn't have as clean a take-home message as the one above).

* resources
https://towardsdatascience.com/deep-learning-for-time-series-classification-inceptiontime-245703f422db
fawaz2019a and fawaz2019b
lines2016
https://arxiv.org/pdf/1909.04939.pdf
https://github.com/twosigma/flint
https://www.deeplearningbook.org/
https://learning.oreilly.com/library/view/deep-learning-with/9781617294433/OEBPS/Text/title.xhtml
https://towardsdatascience.com/how-to-train-your-neural-networks-in-parallel-with-keras-and-apache-spark-ea8a3f48cae6
